{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster_descriptions = pd.read_csv('data/disaster/disaster_descriptions.csv')\n",
    "disaster_points = pd.read_csv('data/disaster/disaster_points.csv')\n",
    "disaster_outlines = gpd.read_file('data/disaster/disaster_outlines/disaster_outlines.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_outlines = gpd.read_file('data/states/state_outlines.shp')\n",
    "county_outlines = gpd.read_file('data/counties/county_outlines.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_state = pd.read_csv('data/housing/mid/housing_state.csv')\n",
    "housing_county = pd.read_csv('data/housing/mid/housing_county.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>point_id</th>\n",
       "      <th>geo_id</th>\n",
       "      <th>level</th>\n",
       "      <th>location</th>\n",
       "      <th>disastertype</th>\n",
       "      <th>disaster_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>State</th>\n",
       "      <th>state_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Colquitt</td>\n",
       "      <td>storm</td>\n",
       "      <td>2000-0067</td>\n",
       "      <td>31.188071</td>\n",
       "      <td>-83.770180</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>storm</td>\n",
       "      <td>2000-0067</td>\n",
       "      <td>31.224709</td>\n",
       "      <td>-84.194102</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>flood</td>\n",
       "      <td>2000-0297</td>\n",
       "      <td>34.442692</td>\n",
       "      <td>-87.842783</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Gasconade</td>\n",
       "      <td>flood</td>\n",
       "      <td>2000-0297</td>\n",
       "      <td>38.442828</td>\n",
       "      <td>-91.507794</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Columbia</td>\n",
       "      <td>storm</td>\n",
       "      <td>2000-0338</td>\n",
       "      <td>33.214327</td>\n",
       "      <td>-93.227224</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>2477</td>\n",
       "      <td>683</td>\n",
       "      <td>1</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>storm</td>\n",
       "      <td>2018-0457</td>\n",
       "      <td>46.352988</td>\n",
       "      <td>-94.195755</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>2478</td>\n",
       "      <td>646</td>\n",
       "      <td>1</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>storm</td>\n",
       "      <td>2018-0457</td>\n",
       "      <td>31.077543</td>\n",
       "      <td>-92.011703</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>2479</td>\n",
       "      <td>690</td>\n",
       "      <td>1</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>storm</td>\n",
       "      <td>2018-0457</td>\n",
       "      <td>34.421536</td>\n",
       "      <td>-106.107856</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>2480</td>\n",
       "      <td>694</td>\n",
       "      <td>1</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>storm</td>\n",
       "      <td>2018-0457</td>\n",
       "      <td>42.076079</td>\n",
       "      <td>-93.500180</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>IA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>2481</td>\n",
       "      <td>675</td>\n",
       "      <td>1</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>storm</td>\n",
       "      <td>2018-0457</td>\n",
       "      <td>35.844194</td>\n",
       "      <td>-86.342432</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2482 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      point_id  geo_id  level    location disastertype disaster_id   latitude  \\\n",
       "0            0       0      2    Colquitt        storm   2000-0067  31.188071   \n",
       "1            1       1      2    Mitchell        storm   2000-0067  31.224709   \n",
       "2            2       2      2    Franklin        flood   2000-0297  34.442692   \n",
       "3            3       3      2   Gasconade        flood   2000-0297  38.442828   \n",
       "4            4       4      2    Columbia        storm   2000-0338  33.214327   \n",
       "...        ...     ...    ...         ...          ...         ...        ...   \n",
       "2477      2477     683      1   Minnesota        storm   2018-0457  46.352988   \n",
       "2478      2478     646      1   Louisiana        storm   2018-0457  31.077543   \n",
       "2479      2479     690      1  New Mexico        storm   2018-0457  34.421536   \n",
       "2480      2480     694      1        Iowa        storm   2018-0457  42.076079   \n",
       "2481      2481     675      1   Tennessee        storm   2018-0457  35.844194   \n",
       "\n",
       "       longitude       State state_id  \n",
       "0     -83.770180     Georgia       GA  \n",
       "1     -84.194102     Georgia       GA  \n",
       "2     -87.842783    Missouri       MO  \n",
       "3     -91.507794    Missouri       MO  \n",
       "4     -93.227224   Wisconsin       WI  \n",
       "...          ...         ...      ...  \n",
       "2477  -94.195755   Minnesota       MN  \n",
       "2478  -92.011703   Louisiana       LA  \n",
       "2479 -106.107856  New Mexico       NM  \n",
       "2480  -93.500180        Iowa       IA  \n",
       "2481  -86.342432   Tennessee       TN  \n",
       "\n",
       "[2482 rows x 10 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disaster_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_to_id = housing_state[['State', 'state_id']]\n",
    "# disaster_points.merge(state_to_id.drop_duplicates(), left_on='state', right_on='State', how='left').drop(columns=['state']).to_csv('data/disaster/disaster_points.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#housing_state.loc[housing_state['Date'] < '2019-01-01'].to_csv('data/housing/mid/housing_state.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#housing_county.loc[housing_county['Date'] < '2019-01-01'].rename({'RegionName': 'County', 'State': 'state_id'}, axis='columns').to_csv('data/housing/mid/housing_county.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# housing_county = (housing_county\n",
    "# .rename({'RegionName': 'County', 'State': 'state_id'})\n",
    "# .loc[housing_county['Value'].notna()]\n",
    "# .astype({'county_id': 'float64'}))\n",
    "# housing_county.to_csv('data/housing/mid/housing_county.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# housing_us = (housing_us\n",
    "#     .rename({'RegionName': 'State'}, axis='columns')\n",
    "#     .assign(state_id='USA'))\n",
    "# pd.concat([housing_state, housing_us]).to_csv('data/housing/mid/housing_state.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# states = state_outlines[['state_id', 'STUSPS']]\n",
    "# states['state_id'] = states['state_id'].astype('int64')\n",
    "# housing_state = housing_state.merge(states, on='state_id')\n",
    "# housing_state.drop(columns=['state_id']).rename({'STUSPS': 'state_id'}, axis='columns').to_csv('data/housing/mid/housing_state.csv', index=False)\n",
    "\n",
    "# state_outlines.drop(columns=['state_id']).rename({'STUSPS': 'state_id'}, axis='columns').to_file('data/states/state_outlines.shp', driver='ESRI Shapefile')\n",
    "# county_outlines.rename({'STUSPS': 'state_id', 'NAMELSAD': 'County'}, axis='columns').astype({'county_id': 'float64'}).to_file('data/counties/county_outlines.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# states = state_outlines[['state_id', 'STUSPS']]\n",
    "# states['state_id'] = states['state_id'].astype('int64')\n",
    "# disaster_to_state = disaster_to_state.merge(states, on='state_id')\n",
    "\n",
    "# county_to_state = county_outlines[['STUSPS', 'county_id']]\n",
    "# disaster_to_county = disaster_to_county.merge(county_to_state, on='county_id')\n",
    "\n",
    "# disaster_to_state = disaster_to_state.merge(disaster_to_county, on=['disaster_id', 'STUSPS'], how='outer')[['disaster_id', 'STUSPS']].drop_duplicates()\n",
    "# test = disaster_descriptions.merge(disaster_to_state, on='disaster_id', how='inner')\n",
    "# test = test.merge(disaster_to_county, on= ['disaster_id', 'STUSPS'], how='left')\n",
    "# test.rename({'STUSPS': 'state_id'}, axis='columns').drop(columns=['Start Year', 'Start Month', 'Start Day', 'End Year', 'End Month', 'End Day']).to_csv('data/disaster/disaster_descriptions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fuzzywuzzy import fuzz\n",
    "# from fuzzywuzzy import process\n",
    "\n",
    "# fuzzytable = housing_county.loc[housing_county['county_id'].isna()]\n",
    "# fuzzytable = fuzzytable.groupby(['State', 'RegionName']).count()['county_id'].reset_index()\n",
    "\n",
    "# county = county_outlines[['STUSPS', 'NAMELSAD', 'county_id']]\n",
    "# def fuzzy_merge(df_1, df_2, state, key1, key2, threshold=90, limit=1):\n",
    "#     \"\"\"\n",
    "#     :param df_1: the left table to join\n",
    "#     :param df_2: the right table to join\n",
    "#     :param key1: key column of the left table\n",
    "#     :param key2: key column of the right table\n",
    "#     :param threshold: how close the matches should be to return a match, based on Levenshtein distance\n",
    "#     :param limit: the amount of matches that will get returned, these are sorted high to low\n",
    "#     :return: dataframe with boths keys and matches\n",
    "#     \"\"\"\n",
    "#     s = df_2[key2].tolist()\n",
    "    \n",
    "#     m = df_1[key1].apply(lambda x: process.extract(x, s, limit=limit))    \n",
    "#     df_1['matches'] = m\n",
    "    \n",
    "#     m2 = df_1['matches'].apply(lambda x: ', '.join([i[0] for i in x if i[1] >= threshold]))\n",
    "#     df_1['matches'] = m2\n",
    "    \n",
    "#     return df_1\n",
    "\n",
    "# states = ['AK', 'AL', 'AR', 'CT', 'FL', 'GA', 'IA', 'IL', 'IN', 'LA', 'MD',\n",
    "#        'MI', 'MN', 'MO', 'ND', 'NM', 'NY', 'TN', 'TX', 'VA', 'WI']\n",
    "\n",
    "# for state in states:\n",
    "#     fuzzy_merge(fuzzytable.loc[fuzzytable['State'] == state], county.loc[county['STUSPS'] == state], state, 'RegionName', 'NAMELSAD', 90)\n",
    "\n",
    "# df1 = fuzzy_merge(fuzzytable, county, 'join', 'join', 90)\n",
    "# df1.to_csv('test.csv')\n",
    "# county['join'] = county['STUSPS'] + ' ' + county['NAMELSAD']\n",
    "# df1 = pd.read_csv('test.csv')\n",
    "# test = housing_county.merge(df1.merge(county, left_on='matches', right_on='join', how='inner'), left_on=['State', 'RegionName'], right_on=['State', 'RegionName'], how='left')\n",
    "# test.loc[test['county_id'].isna(), 'county_id'] = test['county_id_y']\n",
    "# test = test[['RegionName', 'State', 'county_id', 'Date', 'Value']]\n",
    "# test.to_csv('data/housing/mid/housing_county.csv', index=False)\n",
    "# housing_county.loc[housing_county['county_id'].notna()].to_csv('data/housing/mid/housing_county.csv', index=False)\n",
    "\n",
    "# housing_county['county_id'] = housing_county['county_id'].astype('int64')\n",
    "# housing_county.to_csv('data/housing/mid/housing_county.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
